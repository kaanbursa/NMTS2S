{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from pipeline import *\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder for the model\n",
    "\n",
    "### Summary\n",
    "#### Architecture\n",
    "1. Embedding Layer with the size of **(source_vocab_len, desired_embedding_size)**\n",
    "2. Bidirectional GRU unit with size **(desires_embedding_size, desired_hidden_layer_size)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTEncoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\n",
    "        super(NMTEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_size,rnn_hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x, x_len):\n",
    "        embedded = self.embedding(x)\n",
    "        # Create packed sequence\n",
    "        x_len = x.len.detach().cpu().numpy()\n",
    "        x_packed = pack_padded_sequence(embedded, x_len, batch_first=True)\n",
    "        \n",
    "        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\n",
    "        x_birnn_out, x_birnn_h = self.gru(x_packed)\n",
    "        # permute to (batchs, num_rnn, feature_size)\n",
    "        x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
    "        \n",
    "        #flatten (bz, rnn_hid * feat_size)\n",
    "        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0),-1)\n",
    "        \n",
    "        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first = True)\n",
    "        return x_unpacked, x_birnn_h\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "     Args:\n",
    "        num_embeddings (int): number of embeddings; also the number of unique words in the target vocabulary\n",
    "        embedding_size (int): size of the embedding vector \n",
    "        rnn_hidden_size (int): size of the hidden RNN state bos_index(int): BEGIN-OF-SEQUENCE index\n",
    "    \"\"\"\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        self.t_embedding = nn.Embedding(num_embeddings, embeddings_size, padding_idx=0)\n",
    "        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, rnn_hidden_size)\n",
    "        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2,num_embeddings)\n",
    "        self.bos_index = bos_index\n",
    "        \n",
    "        \n",
    "    def _init_indices(self, batch_size):\n",
    "        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
    "    \n",
    "    \n",
    "    def _init_context_vectors(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.__rnn_hidden_size)\n",
    "    \n",
    "    def forward(self, encoder_state, init_hidden_state, target_seq):\n",
    "        \"\"\"The forward pass of the model\n",
    "        Args:\n",
    "            encoder_state (torch.Tensor): output of the NMTEncoder \n",
    "            initial_hidden_state (torch.Tensor): last hidden state in the NMTEn \n",
    "            target_sequence (torch.Tensor): target text data tensor \n",
    "            sample_probability (float): schedule sampling parameter\n",
    "            probability of using model's predictions at each decoder step \n",
    "        Returns:\n",
    "            output_vectors (torch.Tensor): prediction vectors at each output st\n",
    "        \"\"\"\n",
    "        if target_set is None: \n",
    "            sample_probability = 1.0\n",
    "        else:\n",
    "            # The input is (batch, Seq)\n",
    "            # We iterate and permute to (S, B)\n",
    "            target_seq = target_seq.permute(1,0)\n",
    "            output_sequence_size = target_seq.size(0)\n",
    "        \n",
    "        target_seq = target_seq.permute(1,0)\n",
    "        \n",
    "        batch_size = encoder_state.size(0)\n",
    "        \n",
    "        h_t = self.hidden_map(initial_hidden_state)\n",
    "        \n",
    "        context_vectors = self._init_context_vectors(batch_size)\n",
    "        \n",
    "        y_t_indices = self._init_indices(batch_size)\n",
    "        \n",
    "        h_t = h_t.to(encoder_state.device)\n",
    "        y_t_index = y_t_index.to(encoder_state.device)\n",
    "        \n",
    "        context_vectors = context_vectors.to(encoder_state.device)\n",
    "        \n",
    "        output_vectors = []\n",
    "        self._cached_p_attn = []\n",
    "        self._cached_ht = []\n",
    "        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
    "        \n",
    "        output_sequence_size = target_sequence.size(0)\n",
    "        # iterate through each output of encoder rnn\n",
    "        for i in range(output_sequence_size):\n",
    "            use_sample = np.random.random() < sample_probability\n",
    "            \n",
    "            if not use_sample:\n",
    "                y_t_index = target_sequence[i]\n",
    "            \n",
    "            # Step 1: Embed word and concat with previous context\n",
    "            y_input_vector = self.t_embedding(y_t_index)\n",
    "                \n",
    "            rnn_input = torch.cat([y_input_vector, context_vectors],dim=1)\n",
    "\n",
    "            # Step 2: Make a GRU step, getting a new hidden vector\n",
    "            h_t = self.gru_cell(rnn_input, h_t)\n",
    "            self._cached_ht.append(h_t)\n",
    "\n",
    "            # Step 3: Use current hidden vector to attend to atten encoder state\n",
    "            context_vectors, p_attn, _ = verbose_attention(encoder_state_vectors = encoder_state, \n",
    "                                                          query_vector=h_t)\n",
    "\n",
    "            # auxillary: cache the attention probabilities for vis\n",
    "            self.cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
    "\n",
    "            # Step 4: use current context vector and hidden state for prediction\n",
    "            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
    "            score_for_y_t_index = self.classifier(prediction_vector)\n",
    "            if use_sample:\n",
    "                # sampling temperature forces a peakier distribution\n",
    "                p_y_t_index = F.softmax(score_for_y_t_index * self._sampling_temperature, dim=1)\n",
    "                # choose most likely word\n",
    "                _, y_t_index = torch.max(p_y_t_index,1)\n",
    "                # sample from dist\n",
    "                y_t_index = torch.multinomial(p_y_t_index, 1).squeeze()\n",
    "            \n",
    "            output_vectors.append(score_for_y_t_index)\n",
    "            \n",
    "            \n",
    "        output_vectors = torch.stack(outpu_vectors).permute(1,0,2)\n",
    "        return output_vectors\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose_attention(decoder_h_s, encoder_state):\n",
    "    batch_size, num_vectors, vector_size = encoder_state.size()\n",
    "    \n",
    "    vector_scores = torch.sum(decoder_h_s * encoder_state.view(batch_size,1,vector_size), dim=2)\n",
    "    probabilities = F.softmax(vector_scores, dim=1)\n",
    "    weighted_vectors = encoder_state * probabilites.view(batch_size,num_vectors , 1)\n",
    "    context_vectors = torch.sum(weighted_vectors,dim=1)\n",
    "    return context_vectors, probabilities\n",
    "\n",
    "\n",
    "def terse_attention(encoder_state, query):\n",
    "    \"\"\"A shorter and more optimized version of the neural attention mechanism\n",
    "    \n",
    "    Args:\n",
    "        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder\n",
    "        query_vector (torch.Tensor): hidden state\n",
    "    \"\"\"\n",
    "    \n",
    "    torch_scores = torch.matmul(encoder_state, query.unsqueeze(dim=2)).squeeze()\n",
    "    probabilities = F.softmax(torch_scores)\n",
    "    context_vectors = torch.matmul(encoder_state.transpose(-2,-1), probabilities.unsqueeze(dim=2)).squeeze()\n",
    "    return context_vectors, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    \"\"\" A Neural Translation Model\"\"\"\n",
    "    def __init__(self, source_vocab_size, source_embedding_size, target_vocab_size, target_embedding_size, \n",
    "                encoding_size, target_bos_index):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source_vocab_size (int): number of unique words in source vocabulary\n",
    "            source_embedding_size (int): size of embedding vector\n",
    "            target_vocab_size(int): number of unique words in target vocabulary\n",
    "            target_embeddiing_size (int): size of target embedding vector\n",
    "            encoding_size (int): size of encoder RNN\n",
    "            target_bos_index (int): index for BEGIN-OF-SEQUENCE token\n",
    "        \"\"\"\n",
    "        \n",
    "        super(NMTModel,self).__init__()\n",
    "        self.encoder = NMTEncoder(num_embeddings=source_vocab_size,\n",
    "                                 embedding_size=source_embedding_size,\n",
    "                                 rnn_hiden_size= encoding_size)\n",
    "        decoding_size = encoding_size * 2\n",
    "        self.decoder = NMTDecoder(num_embeddings=target_vocab_size,\n",
    "                                 embedding_size=target_embedding_size,\n",
    "                                 rnn_hidden_size=decoding_size)\n",
    "        \n",
    "    def forward(self, x_source, x_source_lengths, target_sequence):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \n",
    "        Args:\n",
    "            x_source (torch.Tensor): the source text data tensor. \n",
    "                x_source.shape should be (batch, vectorizer.max_source_length)\n",
    "            x_source_lengths torch.Tensor): the length of the sequences in x_source \n",
    "            target_sequence (torch.Tensor): the target text data tensor\n",
    "        Returns:\n",
    "            decoded_states (torch.Tensor): prediction vectors at each output step\n",
    "        \"\"\"\n",
    "        encoder_state, hidden_state = self.encoder(x_source, x_source_lengths)\n",
    "        decoder_out = self.decoder(encoder_state, hidden_state, target_sequence)\n",
    "        \n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(dataset_csv=\"data/simplest_eng_fra.csv\",\n",
    "                 vectorizer_file=\"vectorizer.json\",\n",
    "                 model_state_file=\"model.pth\",\n",
    "                 save_dir=\"model_storage/\",\n",
    "                 reload_from_files=True,\n",
    "                 expand_filepaths_to_save_dir=True,\n",
    "                 cuda=False,\n",
    "                 seed=1337,\n",
    "                 learning_rate=5e-4,\n",
    "                 batch_size=32,\n",
    "                 num_epochs=100,\n",
    "                 early_stopping_criteria=5,              \n",
    "                 source_embedding_size=64, \n",
    "                 target_embedding_size=64,\n",
    "                 encoding_size=64,\n",
    "                 catch_keyboard_interrupt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/vectorizer.json\n",
      "\tmodel_storage/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = NMTDataset.load_dataset_and_load_vectorizer(args.dataset_csv, args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'rnn_hiden_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8b62c2fec43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mtarget_embedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_embedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mencoding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  target_bos_index=vectorizer.target_vocab.begin_seq_index)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_from_files\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_state_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-56c5ce1fc1b6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_vocab_size, source_embedding_size, target_vocab_size, target_embedding_size, encoding_size, target_bos_index)\u001b[0m\n\u001b[1;32m     17\u001b[0m         self.encoder = NMTEncoder(num_embeddings=source_vocab_size,\n\u001b[1;32m     18\u001b[0m                                  \u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_embedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                  rnn_hiden_size= encoding_size)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdecoding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         self.decoder = NMTDecoder(num_embeddings=target_vocab_size,\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'rnn_hiden_size'"
     ]
    }
   ],
   "source": [
    "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab), \n",
    "                 source_embedding_size=args.source_embedding_size, \n",
    "                 target_vocab_size=len(vectorizer.target_vocab),\n",
    "                 target_embedding_size=args.target_embedding_size, \n",
    "                 encoding_size=args.encoding_size,\n",
    "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)\n",
    "\n",
    "if args.reload_from_files and os.path.exists(args.model_state_file):\n",
    "    model.load_state_dict(torch.load(args.model_state_file))\n",
    "    print(\"Reloaded model\")\n",
    "else:\n",
    "    print(\"New model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

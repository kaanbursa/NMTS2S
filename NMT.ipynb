{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from pipeline import *\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder for the model\n",
    "\n",
    "### Summary\n",
    "#### Architecture\n",
    "1. Embedding Layer with the size of **(source_vocab_len, desired_embedding_size)**\n",
    "2. Bidirectional GRU unit with size **(desires_embedding_size, desired_hidden_layer_size)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTEncoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\n",
    "        super(NMTEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x, x_len):\n",
    "        embedded = self.embedding(x)\n",
    "        # Create packed sequence\n",
    "        x_len = x_len.detach().cpu().numpy()\n",
    "        x_packed = pack_padded_sequence(embedded, x_len, batch_first=True)\n",
    "        \n",
    "        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\n",
    "        x_birnn_out, x_birnn_h = self.gru(x_packed)\n",
    "        # permute to (batchs, num_rnn, feature_size)\n",
    "        x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
    "        \n",
    "        #flatten (bz, rnn_hid * feat_size)\n",
    "        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0),-1)\n",
    "        \n",
    "        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first = True)\n",
    "        return x_unpacked, x_birnn_h\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "     Args:\n",
    "        num_embeddings (int): number of embeddings; also the number of unique words in the target vocabulary\n",
    "        embedding_size (int): size of the embedding vector \n",
    "        rnn_hidden_size (int): size of the hidden RNN state bos_index(int): BEGIN-OF-SEQUENCE index\n",
    "    \"\"\"\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        \n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "        self.t_embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=0)\n",
    "        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, rnn_hidden_size)\n",
    "        \n",
    "        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        \n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2,num_embeddings)\n",
    "        self.bos_index = bos_index\n",
    "        self._sampling_temperature = 3\n",
    "        \n",
    "        \n",
    "    def _init_indices(self, batch_size):\n",
    "        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
    "    \n",
    "    \n",
    "    def _init_context_vectors(self, batch_size):\n",
    "        return torch.zeros(batch_size, self._rnn_hidden_size)\n",
    "    \n",
    "    def forward(self, encoder_state, initial_hidden_state, target_seq, sample_probability=0.0):\n",
    "        \"\"\"The forward pass of the model\n",
    "        Args:\n",
    "            encoder_state (torch.Tensor): output of the NMTEncoder \n",
    "            initial_hidden_state (torch.Tensor): last hidden state in the NMTEn \n",
    "            target_sequence (torch.Tensor): target text data tensor \n",
    "            sample_probability (float): schedule sampling parameter\n",
    "            probability of using model's predictions at each decoder step \n",
    "        Returns:\n",
    "            output_vectors (torch.Tensor): prediction vectors at each output st\n",
    "        \"\"\"\n",
    "        \n",
    "        if target_seq is None: \n",
    "            sample_probability = 1.0\n",
    "        else:\n",
    "            # The input is (batch, Seq)\n",
    "            # We iterate and permute to (S, B)\n",
    "            target_seq = target_seq.permute(1,0)\n",
    "            output_sequence_size = target_seq.size(0)\n",
    "        \n",
    "        #target_seq = target_seq.permute(1,0)\n",
    "        \n",
    "        batch_size = encoder_state.size(0)\n",
    "        \n",
    "        h_t = self.hidden_map(initial_hidden_state)\n",
    "        \n",
    "        context_vectors = self._init_context_vectors(batch_size)\n",
    "        \n",
    "        y_t_index = self._init_indices(batch_size)\n",
    "        \n",
    "        h_t = h_t.to(encoder_state.device)\n",
    "        y_t_index = y_t_index.to(encoder_state.device)\n",
    "        \n",
    "        context_vectors = context_vectors.to(encoder_state.device)\n",
    "        \n",
    "        output_vectors = []\n",
    "        self._cached_p_attn = []\n",
    "        self._cached_ht = []\n",
    "        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
    "        \n",
    "        output_sequence_size = target_seq.size(0)\n",
    "        # iterate through each output of encoder rnn\n",
    "        for i in range(output_sequence_size):\n",
    "            use_sample = np.random.random() < sample_probability\n",
    "            \n",
    "            if not use_sample:\n",
    "                \n",
    "                y_t_index = target_seq[i]\n",
    "            \n",
    "            # Step 1: Embed word and concat with previous context\n",
    "            y_input_vector = self.t_embedding(y_t_index)\n",
    "            \n",
    "            rnn_input = torch.cat([y_input_vector, context_vectors],dim=1)\n",
    "\n",
    "            # Step 2: Make a GRU step, getting a new hidden vector\n",
    "            h_t = self.gru_cell(rnn_input, h_t)\n",
    "            self._cached_ht.append(h_t)\n",
    "\n",
    "            # Step 3: Use current hidden vector to attend to atten encoder state\n",
    "            context_vectors, p_attn, _ = verbose_attention(encoder_state = encoder_state, \n",
    "                                                          query=h_t)\n",
    "\n",
    "            # auxillary: cache the attention probabilities for vis\n",
    "            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
    "\n",
    "            # Step 4: use current context vector and hidden state for prediction\n",
    "            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
    "            score_for_y_t_index = self.classifier(prediction_vector)\n",
    "            if use_sample:\n",
    "                # sampling temperature forces a peakier distribution\n",
    "                p_y_t_index = F.softmax(score_for_y_t_index * self._sampling_temperature, dim=1)\n",
    "                # choose most likely word\n",
    "                _, y_t_index = torch.max(p_y_t_index,1)\n",
    "                # sample from dist\n",
    "                y_t_index = torch.multinomial(p_y_t_index, 1).squeeze()\n",
    "            \n",
    "            output_vectors.append(score_for_y_t_index)\n",
    "            \n",
    "            \n",
    "        output_vectors = torch.stack(output_vectors).permute(1,0,2)\n",
    "        return output_vectors\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose_attention(encoder_state,query):\n",
    "    batch_size, num_vectors, vector_size = encoder_state.size()\n",
    "    \n",
    "    vector_scores = torch.sum(encoder_state * query.view(batch_size,1,vector_size), dim=2)\n",
    "    probabilities = F.softmax(vector_scores, dim=1)\n",
    "    weighted_vectors = encoder_state * probabilities.view(batch_size,num_vectors , 1)\n",
    "    context_vectors = torch.sum(weighted_vectors,dim=1)\n",
    "    return context_vectors, probabilities, vector_scores\n",
    "\n",
    "\n",
    "def terse_attention(encoder_state, query):\n",
    "    \"\"\"A shorter and more optimized version of the neural attention mechanism\n",
    "    \n",
    "    Args:\n",
    "        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder\n",
    "        query_vector (torch.Tensor): hidden state\n",
    "    \"\"\"\n",
    "    \n",
    "    torch_scores = torch.matmul(encoder_state, query.unsqueeze(dim=2)).squeeze()\n",
    "    probabilities = F.softmax(torch_scores)\n",
    "    context_vectors = torch.matmul(encoder_state.transpose(-2,-1), probabilities.unsqueeze(dim=2)).squeeze()\n",
    "    return context_vectors, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    \"\"\" A Neural Translation Model\"\"\"\n",
    "    def __init__(self, source_vocab_size, source_embedding_size, target_vocab_size, target_embedding_size, \n",
    "                encoding_size, target_bos_index):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source_vocab_size (int): number of unique words in source vocabulary\n",
    "            source_embedding_size (int): size of embedding vector\n",
    "            target_vocab_size(int): number of unique words in target vocabulary\n",
    "            target_embeddiing_size (int): size of target embedding vector\n",
    "            encoding_size (int): size of encoder RNN\n",
    "            target_bos_index (int): index for BEGIN-OF-SEQUENCE token\n",
    "        \"\"\"\n",
    "        \n",
    "        super(NMTModel,self).__init__()\n",
    "        self.encoder = NMTEncoder(num_embeddings=source_vocab_size,\n",
    "                                 embedding_size=source_embedding_size,\n",
    "                                 rnn_hidden_size = encoding_size)\n",
    "        decoding_size = encoding_size * 2\n",
    "        self.decoder = NMTDecoder(num_embeddings=target_vocab_size,\n",
    "                                 embedding_size=target_embedding_size,\n",
    "                                 rnn_hidden_size=decoding_size,\n",
    "                                 bos_index=target_bos_index)\n",
    "        \n",
    "    def forward(self, x_source, x_source_lengths, target_sequence):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \n",
    "        Args:\n",
    "            x_source (torch.Tensor): the source text data tensor. \n",
    "                x_source.shape should be (batch, vectorizer.max_source_length)\n",
    "            x_source_lengths torch.Tensor): the length of the sequences in x_source \n",
    "            target_sequence (torch.Tensor): the target text data tensor\n",
    "        Returns:\n",
    "            decoded_states (torch.Tensor): prediction vectors at each output step\n",
    "        \"\"\"\n",
    "        encoder_state, hidden_state = self.encoder(x_source, x_source_lengths)\n",
    "        decoder_out = self.decoder(encoder_state, hidden_state, target_sequence)\n",
    "        \n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(dataset_csv=\"data/simplest_eng_fra.csv\",\n",
    "                 vectorizer_file=\"vectorizer.json\",\n",
    "                 model_state_file=\"model.pth\",\n",
    "                 save_dir=\"model_storage/\",\n",
    "                 reload_from_files=True,\n",
    "                 expand_filepaths_to_save_dir=True,\n",
    "                 cuda=False,\n",
    "                 seed=1337,\n",
    "                 learning_rate=5e-4,\n",
    "                 batch_size=64,\n",
    "                 num_epochs=100,\n",
    "                 early_stopping_criteria=5,              \n",
    "                 source_embedding_size=64, \n",
    "                 target_embedding_size=64,\n",
    "                 encoding_size=64,\n",
    "                 catch_keyboard_interrupt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/vectorizer.json\n",
      "\tmodel_storage/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = NMTDataset.load_dataset_and_load_vectorizer(args.dataset_csv, args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model\n"
     ]
    }
   ],
   "source": [
    "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab), \n",
    "                 source_embedding_size=args.source_embedding_size, \n",
    "                 target_vocab_size=len(vectorizer.target_vocab),\n",
    "                 target_embedding_size=args.target_embedding_size, \n",
    "                 encoding_size=args.encoding_size,\n",
    "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)\n",
    "\n",
    "if args.reload_from_files and os.path.exists(args.model_state_file):\n",
    "    model.load_state_dict(torch.load(args.model_state_file))\n",
    "    print(\"Reloaded model\")\n",
    "else:\n",
    "    print(\"New model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanb\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a91057eb72a4662b76da4b5d2bffa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanb\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a48a57145f4fefbf9c850810c2d812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=142.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanb\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17363a1d0fd3409898616a420ee27bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=30.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "mask_index = vectorizer.target_vocab.mask_index\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_nmt_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            optimizer.zero_grad()\n",
    "     \n",
    "            y_pred = model(batch_dict['x_source'], batch_dict['x_source_length'], batch_dict['x_target'])\n",
    "            \n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            \n",
    "            train_bar.update()\n",
    "            \n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "        \n",
    "        # iterate over val set\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_nmt_batches(dataset, batch_size=args.batch_size,device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            \n",
    "            \n",
    "            y_pred = model(batch_dict['x_source'], batch_dict['x_source_length'], batch_dict['x_target'])\n",
    "            \n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            \n",
    "            val_bar.update()\n",
    "        \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "        \n",
    "        train_state = update_train_state(args=args, model=model, train_state=train_state)\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        \n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.set_postfix(best_val=train_state['early_stopping_best_val'])\n",
    "        epoch_bar.update()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('Exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMTModel(\n",
       "  (encoder): NMTEncoder(\n",
       "    (embedding): Embedding(3025, 64, padding_idx=0)\n",
       "    (gru): GRU(64, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): NMTDecoder(\n",
       "    (t_embedding): Embedding(4911, 64, padding_idx=0)\n",
       "    (gru_cell): GRUCell(192, 128)\n",
       "    (hidden_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=4911, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_storage/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import bleu_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_indices(indices, vocab, strict=True, return_string=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            break\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "            \n",
    "    if return_string:\n",
    "        return \" \".join(out)\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "class NMTSampler:\n",
    "    def __init__(self, vectorizer, model):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "        \n",
    "    def apply_to_batch(self, batch_dict):\n",
    "        self._last_batch = batch_dict\n",
    "        y_pred = self.model(x_source=batch_dict['x_source'], x_source_lengths=batch_dict['x_source_length'],\n",
    "                           target_sequence=batch_dict['x_target'])\n",
    "        self._last_batch['y_pred'] = y_pred\n",
    "        \n",
    "        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(1, 0, 2)\n",
    "        self._last_batch['attention'] = attention_batched\n",
    "        \n",
    "    def _get_source_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['x_source'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.source_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "    \n",
    "    def _get_reference_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['y_target'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "    \n",
    "    def _get_sampled_sentence(self, index, return_string=True):\n",
    "        _, all_indices = torch.max(self._last_batch['y_pred'], dim=2)\n",
    "        sentence_indices = all_indices[index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(sentence_indices, vocab, return_string=return_string)\n",
    "    \n",
    "    \n",
    "    def get_ith_item(self, index, return_string=True):\n",
    "        output = {'source': self._get_source_sentence(index, return_string=return_string),\n",
    "                 'reference':self._get_reference_sentence(index, return_string=return_string),\n",
    "                 'sampled': self._get_sampled_sentence(index, return_string=return_string),\n",
    "                 'attention': self._last_batch['attention'][index]\n",
    "                 }\n",
    "        \n",
    "        reference = output['reference']\n",
    "        hypothesis = output['sampled']\n",
    "        if not return_string:\n",
    "            reference =  \" \".join(reference)\n",
    "            hypothesis = \" \".join(hypothesis)\n",
    "            \n",
    "        output['bleu-4'] = bleu_score.sentence_bleu(references=[reference], hypothesis=hypothesis,\n",
    "                                                   smoothing_function=sf.method1)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval().to(args.device)\n",
    "\n",
    "sampler = NMTSampler(vectorizer,model)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size,\n",
    "                                       device=args.device)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for batch_dict in batch_generator:\n",
    "    sampler.apply_to_batch(batch_dict)\n",
    "    for i in range(args.batch_size):\n",
    "        test_results.append(sampler.get_ith_item(i,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18., 18., 21., 17., 10., 15., 15., 12.,  9., 27., 28., 24., 32.,\n",
       "        28., 27., 39., 31., 41., 43., 43., 50., 45., 55., 57., 46., 52.,\n",
       "        60., 64., 48., 59., 54., 44., 50., 51., 55., 46., 27., 48., 60.,\n",
       "        42., 39., 46., 51., 45., 38., 58., 30., 16.,  1., 85.]),\n",
       " array([0.01513086, 0.03482824, 0.05452562, 0.074223  , 0.09392039,\n",
       "        0.11361777, 0.13331515, 0.15301254, 0.17270992, 0.1924073 ,\n",
       "        0.21210468, 0.23180207, 0.25149945, 0.27119683, 0.29089422,\n",
       "        0.3105916 , 0.33028898, 0.34998637, 0.36968375, 0.38938113,\n",
       "        0.40907851, 0.4287759 , 0.44847328, 0.46817066, 0.48786805,\n",
       "        0.50756543, 0.52726281, 0.54696019, 0.56665758, 0.58635496,\n",
       "        0.60605234, 0.62574973, 0.64544711, 0.66514449, 0.68484187,\n",
       "        0.70453926, 0.72423664, 0.74393402, 0.76363141, 0.78332879,\n",
       "        0.80302617, 0.82272355, 0.84242094, 0.86211832, 0.8818157 ,\n",
       "        0.90151309, 0.92121047, 0.94090785, 0.96060523, 0.98030262,\n",
       "        1.        ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([r['bleu-4'] for r in test_results], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in top_results:\n",
    "    plt.figure()\n",
    "    target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
